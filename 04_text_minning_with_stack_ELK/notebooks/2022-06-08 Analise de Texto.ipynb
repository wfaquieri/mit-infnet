{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Texto com Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando o pacote cliente do Elasticsearch\n",
    "\n",
    "Para instalar o pacote do Elasticsearch, use:\n",
    "\n",
    "```\n",
    "pip install elasticsearch\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipefg/.pyenv/versions/3.9.1/envs/infnet/lib/python3.9/site-packages/elasticsearch/_sync/client/__init__.py:395: SecurityWarning: Connecting to 'https://localhost:9200' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n"
     ]
    }
   ],
   "source": [
    "import elasticsearch\n",
    "\n",
    "ES_URL = 'https://localhost:9200'\n",
    "ES_USER = 'elastic'\n",
    "ES_PASS = 'elastic123'\n",
    "\n",
    "client = elasticsearch.Elasticsearch(\n",
    "    ES_URL,\n",
    "    basic_auth=(ES_USER, ES_PASS),\n",
    "    verify_certs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desligando warning para facilitar nossa vida\n",
    "import urllib3\n",
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'df5478436d68',\n",
       " 'cluster_name': 'docker-cluster',\n",
       " 'cluster_uuid': 'uQ077_TxQeGa8WqnucK7qw',\n",
       " 'version': {'number': '8.2.2',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': '9876968ef3c745186b94fdabd4483e01499224ef',\n",
       "  'build_date': '2022-05-25T15:47:06.259735307Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '9.1.0',\n",
       "  'minimum_wire_compatibility_version': '7.17.0',\n",
       "  'minimum_index_compatibility_version': '7.0.0'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(client.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando Configurações de análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [{'token': 'Eu',\n",
       "   'start_offset': 0,\n",
       "   'end_offset': 2,\n",
       "   'type': 'word',\n",
       "   'position': 0},\n",
       "  {'token': 'não',\n",
       "   'start_offset': 3,\n",
       "   'end_offset': 6,\n",
       "   'type': 'word',\n",
       "   'position': 1},\n",
       "  {'token': 'quero',\n",
       "   'start_offset': 7,\n",
       "   'end_offset': 12,\n",
       "   'type': 'word',\n",
       "   'position': 2},\n",
       "  {'token': 'um',\n",
       "   'start_offset': 13,\n",
       "   'end_offset': 15,\n",
       "   'type': 'word',\n",
       "   'position': 3},\n",
       "  {'token': 'copo',\n",
       "   'start_offset': 16,\n",
       "   'end_offset': 20,\n",
       "   'type': 'word',\n",
       "   'position': 4},\n",
       "  {'token': \"d'água.\",\n",
       "   'start_offset': 21,\n",
       "   'end_offset': 28,\n",
       "   'type': 'word',\n",
       "   'position': 5}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = client.indices.analyze(\n",
    "        analyzer=\"whitespace\",\n",
    "        text=\"Eu não quero um copo d'água.\"\n",
    ")\n",
    "dict(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo exemplo, mas deixando o resultado mais legível:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eu', 'não', 'quero', 'um', 'copo', \"d'água.\"]\n"
     ]
    }
   ],
   "source": [
    "analyzed = client.indices.analyze(\n",
    "        analyzer=\"whitespace\",\n",
    "        text=\"Eu não quero um copo d'água.\"\n",
    ")\n",
    "\n",
    "print([x[\"token\"] for x in analyzed['tokens']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O analisador `standard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eu', 'não', 'quero', 'um', 'copo', \"d'água\"]\n"
     ]
    }
   ],
   "source": [
    "analyzed = client.indices.analyze(\n",
    "    analyzer=\"standard\",\n",
    "    text=\"Eu não quero um copo d'água.\"\n",
    ")\n",
    "\n",
    "print([x[\"token\"] for x in analyzed['tokens']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Especificando os componentes individualmente\n",
    "\n",
    "Em vez de especificar um analisador pré-configurado, podemos especificar os componentes individualmente, como abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eu', 'nao', 'quero', 'um', 'copo', \"d'agua\"]\n"
     ]
    }
   ],
   "source": [
    "analyzed = client.indices.analyze(\n",
    "    tokenizer=\"standard\",\n",
    "    filter=['asciifolding', 'lowercase'],\n",
    "    text=\"Eu não quero um copo d'água.\",\n",
    ")\n",
    "\n",
    "print([x[\"token\"] for x in analyzed['tokens']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O filtro `elision` é pensado para o Francês, e retira os prefixos transformando, por exemplo, `l'avion` em `avion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eu', 'nao', 'quero', 'um', 'copo', 'agua']\n"
     ]
    }
   ],
   "source": [
    "analyzed = client.indices.analyze(\n",
    "    tokenizer=\"standard\",\n",
    "    filter=['asciifolding', 'lowercase', 'elision'],\n",
    "    text=\"Eu não quero um copo d'água.\",\n",
    ")\n",
    "\n",
    "print([x[\"token\"] for x in analyzed['tokens']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando um Analyzer customizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"meu_analisador\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"asciifolding\",\n",
    "                        \"lowercase\",\n",
    "                        \"elision\",\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'meu_indice'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if client.indices.exists(index=\"meu_indice\"):\n",
    "    client.indices.delete(index=\"meu_indice\")\n",
    "client.indices.create(index=\"meu_indice\", **index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eu', 'nao', 'quero', 'um', 'copo', 'agua']\n"
     ]
    }
   ],
   "source": [
    "analyzed = client.indices.analyze(\n",
    "    index=\"meu_indice\",\n",
    "    analyzer=\"meu_analisador\",\n",
    "    text=\"Eu não quero um copo d'água.\",\n",
    ")\n",
    "\n",
    "print([x[\"token\"] for x in analyzed['tokens']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando um Analyzer com filtros customizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"meu_analisador\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"elision\",\n",
    "                        \"stop_pt\",\n",
    "                        \"asciifolding\",\n",
    "                        \"stop_custom\",\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"stop_pt\": {\n",
    "                    \"type\": \"stop\",\n",
    "                    \"stopwords\": \"_portuguese_\",\n",
    "                },\n",
    "                \"stop_custom\": {\n",
    "                    \"type\": \"stop\",\n",
    "                    \"stopwords\": ['agua'],\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'meu_indice'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if client.indices.exists(index=\"meu_indice\"):\n",
    "    client.indices.delete(index=\"meu_indice\")\n",
    "client.indices.create(index=\"meu_indice\", **index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quero', 'copo']\n"
     ]
    }
   ],
   "source": [
    "analyzed = client.indices.analyze(\n",
    "    index=\"meu_indice\",\n",
    "    analyzer=\"meu_analisador\",\n",
    "    text=\"Eu não quero um copo d'água.\",\n",
    ")\n",
    "\n",
    "print([x[\"token\"] for x in analyzed['tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"meu_analisador\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"elision\",\n",
    "                        \"radiciacao\",\n",
    "                        #\"stop_pt\",\n",
    "                        #\"asciifolding\",\n",
    "                        #\"stop_custom\",\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"stop_pt\": {\n",
    "                    \"type\": \"stop\",\n",
    "                    \"stopwords\": \"_portuguese_\",\n",
    "                },\n",
    "                \"stop_custom\": {\n",
    "                    \"type\": \"stop\",\n",
    "                    \"stopwords\": ['agua'],\n",
    "                },\n",
    "                \"radiciacao\": {\n",
    "                    \"type\": \"snowball\",\n",
    "                    \"language\": \"Portuguese\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'meu_indice'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if client.indices.exists(index=\"meu_indice\"):\n",
    "    client.indices.delete(index=\"meu_indice\")\n",
    "client.indices.create(index=\"meu_indice\", **index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eu', 'nã', 'quer', 'um', 'cop', 'águ', 'branc', 'branc']\n"
     ]
    }
   ],
   "source": [
    "analyzed = client.indices.analyze(\n",
    "    index=\"meu_indice\",\n",
    "    analyzer=\"meu_analisador\",\n",
    "    text=\"Eu não quero um copo d'água branca branco.\",\n",
    ")\n",
    "\n",
    "print([x[\"token\"] for x in analyzed['tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
